{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 Parallel Search\n",
    "\n",
    "This module investigates two technologies for supporting parallel data analytics in common commercial cloud cyberinfrastructure.\n",
    " 1. GCP BigQuery\n",
    " 2. AWS OpenSearch \n",
    " \n",
    "\n",
    "#### Module Kickoff Video\n",
    "* [Parallel Search Concept Introduction (11 min)](https://youtu.be/FSRIvNniowo)\n",
    " * [Slides](./resources/DSA8430_Parallel_Search.pdf)\n",
    " \n",
    "You will see below that we have organized this module into a Part 1 (GCP BigQuery) and Part 2 (AWS OpenSearch).  \n",
    "Please work through the respective parts in there entirety.\n",
    "These are case studies that are self-contained and independent of each other.\n",
    "**Do not try to do both sets of labs, then practices, then exercises** in the traditional DSA style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Part 1 - GCP BigQuery](./GCP_BigQuery.ipynb)\n",
    "\n",
    "Please ensure you have registered all the associated development artifacts into notebooks and Git for grading.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Part 2 - AWS OpenSearch](./AWS_OpenSearch.ipynb)\n",
    "\n",
    "Please ensure you have registered all the associated development artifacts into notebooks and Git for grading.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A module reflection\n",
    "\n",
    "Now that you have worked through the use of both GCP Big Query and AWS Open Search,\n",
    "contemplate how you could leverage each of these technologies for scalable data storage.\n",
    "In the context of your professional work or research, please provide example paradigms (data and use cases) in which each solution is more appropriate than the other."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#  Add your final module reflection below.\n",
    "\n",
    "For GCP, I see this being a good candidate for something such as daily sales data, or weather reporting. With the structure of the database you could build something containing dma, customer, product segment, daily sales, etc easily and then match that up with say a weather database with similar variables to create a sales forecast tool. \n",
    "\n",
    "For AWS, I would see this being good for a transactional level set of data, such as sales off a website. You could create the .json file format and update based on whenever a consumer purchases off your webste, tracking things such as item bough, time on site, shipping state, payment method, etc. Then you could use the dashboard tool to aggregate and create quick visualizations for management to asses how consumers are using your website for sales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting your work\n",
    "\n",
    "#### Steps:\n",
    "  1. Open Terminal in JupyterHub\n",
    "  1. Change into the course folder\n",
    "  1. Stage (Git Add) the module's learning activities   \n",
    "  `git  add   module3`\n",
    "  1. Create your work snapshot (Git Commit)  \n",
    "  `git   commit   -m   \"All Module 3 work\"`\n",
    "  1. Upload the snapshot to the server (Git Push)  \n",
    "  `git   push`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

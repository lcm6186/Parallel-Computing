{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Classification Modelling on the created dataset using SparkML in GCP DataProc\n",
    "\n",
    "Similar to practices, here we will run code to conduct a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from __future__ import print_function\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect features of interest for the model\n",
    "\n",
    "def vector_from_inputs(r):\n",
    "    return(r[\"transactions\"], Vectors.dense(float(r[\"countryIndex\"]),\n",
    "                                           float(r[\"isMobile\"]),\n",
    "                                           float(r[\"pageviews\"]),\n",
    "                                           float(r[\"operatinSystemIndex\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/08 18:41:28 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "22/04/08 18:41:28 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "22/04/08 18:41:28 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "22/04/08 18:41:28 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get BigQuery Data\n",
    "\n",
    "Since dataset is public we should be able to directly grab it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/08 18:41:38 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "ga_data = spark.read.format(\"bigquery\").option(\n",
    "    \"table\", \"bigquery-public-data.google_analytics_sample.ga_sessions_20170801\").load()\n",
    "# Create a view so that Spark SQL queries can be run against the data.\n",
    "ga_data.createOrReplaceTempView(\"googleAnalytics\")\n",
    "\n",
    "## -------------------ENSURE CLEAN DATA NO NULLS----------------\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT device.operatingSystem, device.isMobile, geoNetwork.country, totals.pageviews, totals.transactions\n",
    "from googleAnalytics\n",
    "where device.operatingSystem is not null\n",
    "and device.isMobile is not null\n",
    "and geoNetwork.country is not null\n",
    "and totals.pageviews is not null\n",
    "and totals.transactions is not null\"\"\"\n",
    "ga_clean = spark.sql(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+-------------+---------+------------+\n",
      "|operatingSystem|isMobile|      country|pageviews|transactions|\n",
      "+---------------+--------+-------------+---------+------------+\n",
      "|      Macintosh|   false|United States|        5|           1|\n",
      "|      Macintosh|   false|United States|       11|           1|\n",
      "|      Macintosh|   false|United States|       14|           1|\n",
      "|      Macintosh|   false|United States|       14|           1|\n",
      "|      Macintosh|   false|United States|       16|           1|\n",
      "|      Macintosh|   false|United States|       14|           1|\n",
      "|      Macintosh|   false|United States|       13|           1|\n",
      "|      Macintosh|   false|United States|       16|           1|\n",
      "|            iOS|    true|      Finland|       18|           1|\n",
      "|      Macintosh|   false|United States|       18|           1|\n",
      "+---------------+--------+-------------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show some results to ensure we got the table\n",
    "\n",
    "ga_clean.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Prep\n",
    "\n",
    "Below we need to ensure data is ready to go for the model. We will: \n",
    "\n",
    "    - conduct indexing/one-hot encoding on categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Once indexed, we can now use a one-hot approach on the data. \\ndata_one_hot = OneHotEncoder(inputCols=['operatinSystemIndex', 'countryIndex'],\\n                       outputCols=['operatingSystemEncoded', 'countryEncoded'])\\n\\ndata_encoded = data_one_hot.fit(data_indexed).transform(data_indexed)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First index columns\n",
    "data_index = StringIndexer(inputCols=['operatingSystem', 'country'], \n",
    "                           outputCols=['operatinSystemIndex', 'countryIndex'])\n",
    "\n",
    "data_indexed = data_index.fit(ga_clean).transform(ga_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+-------------+---------+------------+-------------------+------------+\n",
      "|operatingSystem|isMobile|      country|pageviews|transactions|operatinSystemIndex|countryIndex|\n",
      "+---------------+--------+-------------+---------+------------+-------------------+------------+\n",
      "|      Macintosh|   false|United States|        5|           1|                0.0|         0.0|\n",
      "|      Macintosh|   false|United States|       11|           1|                0.0|         0.0|\n",
      "|      Macintosh|   false|United States|       14|           1|                0.0|         0.0|\n",
      "|      Macintosh|   false|United States|       14|           1|                0.0|         0.0|\n",
      "|      Macintosh|   false|United States|       16|           1|                0.0|         0.0|\n",
      "|      Macintosh|   false|United States|       14|           1|                0.0|         0.0|\n",
      "|      Macintosh|   false|United States|       13|           1|                0.0|         0.0|\n",
      "|      Macintosh|   false|United States|       16|           1|                0.0|         0.0|\n",
      "|            iOS|    true|      Finland|       18|           1|                4.0|         1.0|\n",
      "|      Macintosh|   false|United States|       18|           1|                0.0|         0.0|\n",
      "+---------------+--------+-------------+---------+------------+-------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#View\n",
    "data_indexed.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, combine the columns into a useable dataset\n",
    "\n",
    "model_data = data_indexed.drop(\"operatingSystem\",\"country\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[label: bigint, features: vector]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, move to training data\n",
    "\n",
    "training_data = model_data.rdd.map(vector_from_inputs).toDF([\"label\",\n",
    "                                                             \"features\"])\n",
    "training_data.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On to the classification model\n",
    "\n",
    "Personally I have enjoyed using Random Forests in classes so I have finally decided to run with that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(labelCol = 'label', featuresCol = 'features',\n",
    "                            subsamplingRate = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rfc_model = rfc.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.classification.RandomForestClassificationTrainingSummary at 0x7f707999ca30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9534883720930233"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model.summary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

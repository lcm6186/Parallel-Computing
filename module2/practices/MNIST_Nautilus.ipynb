{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapted 2.6 TF version of MNIST example\n",
    "\n",
    "Required PIP installs on the Nautilus Tensorflow Image\n",
    " * pip install codetiming\n",
    " * pip install tensorflow-datasets\n",
    "Note: These must be done each time the container restarts\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 1,
   "id": "e5b942cd-95ce-42ed-bfd1-51838338126a",
>>>>>>> a5f65ab1d71db64dcd54823fa6b92b4aef0b4cfe
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools, functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from dsa_automation import tf_limit, tf_keras_reset\n",
    "#sess_config = tf_limit(tf, 4, glbs=globals())\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "#tf_keras_reset(tf, sess_config)\n",
    "\n",
    "from sklearn.preprocessing import scale, LabelBinarizer\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random seed for numpy\n",
    "np.random.seed(18937)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 2,
   "id": "c5510119-1030-47f3-a538-75e7218cc0f8",
>>>>>>> a5f65ab1d71db64dcd54823fa6b92b4aef0b4cfe
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice some slight changes for the update from 1.3 to 2.6 Tensorflow"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 3,
   "id": "403a1304-48a9-473d-9f6b-9ea3eadc0c4b",
>>>>>>> a5f65ab1d71db64dcd54823fa6b92b4aef0b4cfe
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 19:21:03.362620: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-26 19:21:03.874057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10343 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "layers = [   \n",
    "    ############################\n",
    "    # Input Prep\n",
    "    ############################\n",
    "\n",
    "    # we define the input as 784 image pixels\n",
    "    ##### NEW TFDS Loading gets data in proper shape\n",
    "#    tf.keras.Input(shape=(784,)),\n",
    "    \n",
    "    # We un-flatten the square image (28x28 pixels) from the vector of values\n",
    "#    tf.keras.layers.Reshape((28, 28, 1)),\n",
    "    tf.keras.Input(shape=input_shape),\n",
    "    \n",
    "    ############################\n",
    "    # Convolutional layers, aka\n",
    "    #   Feature Extraction Phase\n",
    "    ############################\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', padding='SAME'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2), strides=(2,2), padding='SAME'),\n",
    "    \n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (5, 5), activation='relu', padding='SAME'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2), strides=(2,2), padding='SAME'),\n",
    "        \n",
    "    ############################\n",
    "    # Fully connected network\n",
    "    #  aka, Classification Phase\n",
    "    ############################\n",
    "\n",
    "    ######\n",
    "    # STOP : Figure out why this size is 7x7x64 = 3136 features, \n",
    "    #        the math is right above, if you did readings\n",
    "    ######\n",
    "    tf.keras.layers.Reshape((7*7*64,)),\n",
    "    \n",
    "    # A layer of 1024 neurons\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate = 0.5),  # this is the drop-out concept, see readings for how this aids network generalizations\n",
    "    \n",
    "    # The final classification layer, where each \n",
    "    # output is a layer-normalized logistic function\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "]\n",
    "\n",
    "# This function walks throguh the layers composing them into chain of nested functions\n",
    "y_pred = functools.reduce(lambda f1, f2: f2(f1), layers)\n",
    "\n",
    "# Define the model as input, and the function chain that produces the output\n",
    "model = tf.keras.models.Model(inputs = [layers[0]], outputs = [y_pred])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(#optimizer=\"Adam\",\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    #loss='categorical_crossentropy',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note about, we see the logging messages \n",
    "`gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0`\n",
    "\n",
    "#### At the time of development, we are getting an NVIDIA GeForce GTX 1080"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 4,
   "id": "727fac27-d575-4b98-bf85-9d0df660ad5a",
>>>>>>> a5f65ab1d71db64dcd54823fa6b92b4aef0b4cfe
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              3212288   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,274,634\n",
      "Trainable params: 3,274,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's look at this beast!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note the trainable parameters!\n",
    "Over 3 million trainable parameters, which means we need lots of data, computation, and time to learn all these parameters.\n",
    "These are often much more complicated models and therefore more complicated decision surface chains than other machine learning models you have worked with.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "## Load dataset\n",
    "\n",
    "\n",
    "### You will see there are some updates from the Tensorflow 1.3 time.\n",
    "#### This a result of significant changes in TF from 1+ to 2+ versions of the API and the library."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 5,
   "id": "39a06bf3-3faa-4ba7-97b8-266fcb4bc490",
>>>>>>> a5f65ab1d71db64dcd54823fa6b92b4aef0b4cfe
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 19:21:39.140660: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/jovyan/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0818512e68436486c6033b1ba78cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /home/jovyan/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.examples.tutorials import mnist\n",
    "# Notice we are converting the labels to 1-hots\n",
    "#dataset = mnist.input_data.read_data_sets('/dsa/data/all_datasets/MNIST_data', one_hot=True)\n",
    "\n",
    "# From: https://www.tensorflow.org/datasets/keras_example\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 6,
   "id": "05be7c2e-5a12-4306-81ce-9a667f071fb3",
>>>>>>> a5f65ab1d71db64dcd54823fa6b92b4aef0b4cfe
   "metadata": {},
   "outputs": [],
   "source": [
    "# A transformation Function for mapping the \n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(50)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(50)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 7,
   "id": "4e0b7bf3-9514-478d-a987-b375e69a57d8",
>>>>>>> a5f65ab1d71db64dcd54823fa6b92b4aef0b4cfe
   "metadata": {},
   "outputs": [],
   "source": [
    "from codetiming import Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: In the older TF 1.3, the training data was 55,000 samples.\n",
    "### 10 epochs x 55,000 samples = 550,000 image training passes.\n",
    "\n",
    "## In the new TF2.6 the MNIST training data (https://www.tensorflow.org/datasets/catalog/mnist) is 60,000 training samples.\n",
    "### So, we will be pushing a little more data through (extra 50K on GPU), but still close enough fair timing comparison."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 8,
   "id": "bffb60c5-d0de-4f57-8975-c2d701c53b1b",
>>>>>>> a5f65ab1d71db64dcd54823fa6b92b4aef0b4cfe
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "2022-02-26 19:22:22.748145: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 7s 3ms/step - loss: 0.1228 - accuracy: 0.9621 - val_loss: 0.0274 - val_accuracy: 0.9899\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9868 - val_loss: 0.0249 - val_accuracy: 0.9906\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0287 - accuracy: 0.9908 - val_loss: 0.0241 - val_accuracy: 0.9930\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0255 - val_accuracy: 0.9927\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0267 - val_accuracy: 0.9926\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.0320 - val_accuracy: 0.9906\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.0243 - val_accuracy: 0.9932\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.0312 - val_accuracy: 0.9923\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0263 - val_accuracy: 0.9927\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0312 - val_accuracy: 0.9935\n",
      "Elapsed time: 40.0361 seconds\n"
     ]
    }
   ],
   "source": [
    "t = Timer(name=\"class\")\n",
    "t.start()\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    epochs=10,\n",
    "    validation_data=ds_test,\n",
    ")\n",
    "\n",
    "learn_time = t.stop()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 9,
   "id": "c7a2c0df-f93a-4f43-af40-84205fbabfef",
>>>>>>> a5f65ab1d71db64dcd54823fa6b92b4aef0b4cfe
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.036 s used to train the CNN\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.3f} s used to train the CNN\".format(learn_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Artifacts\n",
    "\n",
    "## In the cell below, detail the specifics related to Divide and Conquer and the acceleration of the training by the GPU. Additionally, when you started the training, you may have noticed a slight delay before the training started."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Make note of the Training Times below:\n",
    "\n",
    "CPU (Lab - DSA) : 314.38 seconds\n",
    "GPU (Nautilus) : 40.036 seconds\n",
    "\n",
    "# Add your assessment below this line.\n",
    "\n",
    "For the divide and conquer technique we partition the datasets into smaller sections that then can run in parallel thus drastically reducing computing time and resources. This gives and increase in speed of the model which can help with larger datasets (such as this one with the 3.2MM parameters and 60K samples used). \n",
    "Based on the videos and readings it is not surprising that the GPU console was able to out perform the CPU one as there are more processing cores on the GPU to handle the algorithms in parallel. \n",
    "\n",
    "We also used a NVIDIA GeForce GTX 1080 GPU which by today's standards is even a little out dated. It would be very interesting to see this thing also run for comparison on a more modern piece of hardware (such as a 3080) or other advanced CUDA API. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

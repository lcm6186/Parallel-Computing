{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Module 6: MNIST handwritten digits\n",
    "\n",
    "In this lab, we are going to learn to recognize hand-written digits from the MNIST data set.\n",
    "\n",
    "Before we get started, you need to do a couple things:\n",
    "1. Ensure you are in the Tensorflow CPU container image.  If not, go to your first tab and use the Quit button, then re-access the environment and select the Tensorflow CPU container image.\n",
    "2. Open a Terminal and install the codetiming library: `pip install codetiming`\n",
    "\n",
    "This dataset is the \"IRIS\" data of image analysis neural networks.\n",
    " * http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute(`__notebook_path='${IPython.notebook.notebook_path}'; dsa_automation.notebook_path=__notebook_path`);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools, functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from dsa_automation import tf_limit, tf_keras_reset\n",
    "sess_config = tf_limit(tf, 4, glbs=globals())\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf_keras_reset(tf, sess_config)\n",
    "\n",
    "from sklearn.preprocessing import scale, LabelBinarizer\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random seed for numpy\n",
    "np.random.seed(18937)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisiting Keras\n",
    "\n",
    "Keras is an abstraction of the TensorFlow API to facilitate more easily constructed models.\n",
    "And actually, it is a general Python library for model construction that supports TensorFlow and some other underlying lirbaries. \n",
    "  * https://keras.io/\n",
    "\n",
    "It has since been wrapped into TensorFlow as `tf.keras`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we construct a [Convolutional Neural Network](http://deeplearning.net/tutorial/lenet.html) that has the following structure:\n",
    "  * Convolution with 5x5 pixel kernels, 32 of them, and using the [Rectified Linear Unit](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n",
    "  * Max Pooling with 2x2 kernel: Find the strongest response in each 2x2 neuron area of a generated feature map (from the convolution)\n",
    "     * Good Pooling Page: http://ufldl.stanford.edu/tutorial/supervised/Pooling/\n",
    "  * Convolve with 64 5x5 kernels, then Max Pooling again\n",
    "  * Strecth all the feature maps out into a vector\n",
    "  * A feed forward, fully connected layer -- think just dense vector -- of 1024 neurons\n",
    "  * 10 class activation using SoftMax, a logit layer, with all neurons normalized to sum to 1.0\n",
    "    * https://en.wikipedia.org/wiki/Softmax_function\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [   \n",
    "    ############################\n",
    "    # Input Prep\n",
    "    ############################\n",
    "\n",
    "    # we define the input as 784 image pixels\n",
    "    tf.keras.Input(shape=(784,)),\n",
    "    \n",
    "    # We un-flatten the square image (28x28 pixels) from the vector of values\n",
    "    tf.keras.layers.Reshape((28, 28, 1)),\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    # Convolutional layers, aka\n",
    "    #   Feature Extraction Phase\n",
    "    ############################\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, (5, 5), activation='relu', padding='SAME'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2), strides=(2,2), padding='SAME'),\n",
    "    \n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (5, 5), activation='relu', padding='SAME'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2), strides=(2,2), padding='SAME'),\n",
    "        \n",
    "    ############################\n",
    "    # Fully connected network\n",
    "    #  aka, Classification Phase\n",
    "    ############################\n",
    "\n",
    "    ######\n",
    "    # STOP : Figure out why this size is 7x7x64 = 3136 features, \n",
    "    #        the math is right above, if you did readings\n",
    "    ######\n",
    "    tf.keras.layers.Reshape((7*7*64,)),\n",
    "    \n",
    "    # A layer of 1024 neurons\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate = 0.5),  # this is the drop-out concept, see readings for how this aids network generalizations\n",
    "    \n",
    "    # The final classification layer, where each \n",
    "    # output is a layer-normalized logistic function\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "]\n",
    "\n",
    "# This function walks throguh the layers composing them into chain of nested functions\n",
    "y_pred = functools.reduce(lambda f1, f2: f2(f1), layers)\n",
    "\n",
    "# Define the model as input, and the function chain that produces the output\n",
    "model = tf.keras.models.Model(inputs = [layers[0]], outputs = [y_pred])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,634\n",
      "Trainable params: 3,274,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's look at this beast!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note the trainable parameters!\n",
    "Over 3 million trainable parameters, which means we need lots of data, computation, and time to learn all these parameters.\n",
    "These are often much more complicated models and therefore more complicated decision surface chains than other machine learning models you have worked with.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /dsa/data/all_datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /dsa/data/all_datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /dsa/data/all_datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /dsa/data/all_datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials import mnist\n",
    "# Notice we are converting the labels to 1-hots\n",
    "dataset = mnist.input_data.read_data_sets('/dsa/data/all_datasets/MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not sure what just happened with the `*.gz` files, \n",
    "go back and review the link about the data set.\n",
    "\n",
    "----\n",
    "\n",
    "## Train the model\n",
    "\n",
    "This should look similar to what you have seen in other courses, such as Applied Machine Leanring, \n",
    "just using some different syntatical access to the data and labels \n",
    "because we are using TF instead of SciKit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "55000/55000 [==============================] - 103s 2ms/sample - loss: 0.1312 - categorical_accuracy: 0.9588 - val_loss: 0.0498 - val_categorical_accuracy: 0.9872\n",
      "Epoch 2/3\n",
      "55000/55000 [==============================] - 105s 2ms/sample - loss: 0.0462 - categorical_accuracy: 0.9852 - val_loss: 0.0295 - val_categorical_accuracy: 0.9900\n",
      "Epoch 3/3\n",
      "55000/55000 [==============================] - 106s 2ms/sample - loss: 0.0304 - categorical_accuracy: 0.9908 - val_loss: 0.0446 - val_categorical_accuracy: 0.9898\n",
      "Elapsed time: 314.3766 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from codetiming import Timer\n",
    "t = Timer(name=\"class\")\n",
    "t.start()\n",
    "\n",
    "model.fit(x=[dataset.train.images], # Notice, we have dataset.train, below we will use dataset.test\n",
    "          y=[dataset.train.labels], \n",
    "          batch_size=50, \n",
    "          epochs=3,\n",
    "          validation_data=(dataset.validation.images, dataset.validation.labels), \n",
    "          shuffle=True, \n",
    "          verbose=1)\n",
    "\n",
    "learn_time = t.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314.38 s used to train the CNN\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.2f} s used to train the CNN\".format(learn_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that training time is significantly longer than our prior experience.\n",
    "Welcome to deep learning, and for reference... we are not even *deep* yet!\n",
    "This has 2x convolutional layers.\n",
    "Contemporary models may have over 100 convolutional layers!\n",
    "\n",
    "---\n",
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n",
      " - 6s - loss: 0.0303 - categorical_accuracy: 0.9910\n",
      "loss: 0.0303  accuracy: 0.9910\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation')\n",
    "print('loss: %.4f  accuracy: %.4f' % tuple(\n",
    "    model.evaluate(x=[dataset.test.images], # Note we are using the blind dataset.test\n",
    "                   y=[dataset.test.labels], \n",
    "                   batch_size=50, verbose=2)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Save your notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
